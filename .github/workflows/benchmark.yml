name: Performance Benchmark

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run monthly on the 1st at 2 AM UTC
    - cron: "0 2 1 * *"
  workflow_dispatch:
    inputs:
      duration:
        description: "Benchmark duration in seconds"
        default: "30"
        required: false
      connections:
        description: "Number of connections"
        default: "100"
        required: false
      threads:
        description: "Number of threads"
        default: "4"
        required: false

jobs:
  benchmark:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: "1.21"
          check-latest: true

      - name: Install Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      - name: Install wrk
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk

      - name: Install additional tools
        run: |
          sudo apt-get install -y curl lsof jq

      - name: Setup Go dependencies
        run: |
          cd servers/go-vanilla && go mod tidy
          cd ../go-fiber && go mod tidy

      - name: Setup Bun dependencies
        run: |
          cd servers/hono-bun && bun install

      - name: Make scripts executable
        run: |
          chmod +x scripts/benchmark.sh

      - name: Set benchmark parameters
        run: |
          echo "DURATION=${{ github.event.inputs.duration || '15' }}" >> $GITHUB_ENV
          echo "CONNECTIONS=${{ github.event.inputs.connections || '50' }}" >> $GITHUB_ENV
          echo "THREADS=${{ github.event.inputs.threads || '2' }}" >> $GITHUB_ENV

      - name: Run benchmarks
        run: |
          # Create results directory
          mkdir -p results

          # Run benchmark with CI-friendly parameters
          ./scripts/benchmark.sh \
            --duration ${{ env.DURATION }} \
            --connections ${{ env.CONNECTIONS }} \
            --threads ${{ env.THREADS }}

      - name: Generate README
        run: |
          go run scripts/generate_readme.go

      - name: Check for changes
        id: git-check
        run: |
          git diff --exit-code README.md || echo "changes=true" >> $GITHUB_OUTPUT

      - name: Commit and push changes
        if: steps.git-check.outputs.changes == 'true' && github.event_name != 'pull_request'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add README.md results/
          git commit -m "ðŸš€ Update benchmark results [skip ci]"
          git push

      - name: Create PR comment with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Read the latest results
            const resultsDir = './results';
            const files = fs.readdirSync(resultsDir)
              .filter(f => f.startsWith('benchmark_') && f.endsWith('.json'))
              .sort()
              .reverse();

            if (files.length === 0) {
              console.log('No benchmark results found');
              return;
            }

            const latestFile = path.join(resultsDir, files[0]);
            const results = JSON.parse(fs.readFileSync(latestFile, 'utf8'));

            // Create summary table
            let comment = '## ðŸš€ Benchmark Results\n\n';
            comment += '| Framework | Requests/sec | Avg Latency |\n';
            comment += '|-----------|-------------|-------------|\n';

            // Sort frameworks by performance
            const frameworks = [];
            for (const [framework, endpoints] of Object.entries(results.results)) {
              const rootEndpoint = endpoints.find(ep => ep.endpoint === 'Root endpoint');
              if (rootEndpoint && rootEndpoint.requests_per_sec) {
                const rps = parseFloat(rootEndpoint.requests_per_sec.replace(/[,k]/g, '')) || 0;
                frameworks.push({
                  name: framework.replace(/-/g, ' ').replace(/\b\w/g, l => l.toUpperCase()),
                  rps: rootEndpoint.requests_per_sec,
                  latency: rootEndpoint.avg_latency
                });
              }
            }

            frameworks.forEach(fw => {
              comment += `| **${fw.name}** | ${fw.rps} | ${fw.latency} |\n`;
            });

            comment += '\n---\n';
            comment += `*Benchmark run on ${new Date().toISOString()}*\n`;
            comment += `*Duration: ${results.configuration.duration}s, Connections: ${results.configuration.connections}, Threads: ${results.configuration.threads}*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: results/
          retention-days: 30

      - name: Archive benchmark logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-logs-${{ github.run_number }}
          path: |
            *.log
            /tmp/*.log
          retention-days: 7
          if-no-files-found: ignore

  benchmark-matrix:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest

    permissions:
      contents: write

    strategy:
      matrix:
        config:
          - { duration: 60, connections: 100, threads: 4, name: "standard" }
          - { duration: 30, connections: 200, threads: 8, name: "high-load" }
          - { duration: 120, connections: 50, threads: 2, name: "endurance" }

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: "1.21"

      - name: Install Bun
        uses: oven-sh/setup-bun@v1

      - name: Install wrk and dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk curl lsof jq

      - name: Setup dependencies
        run: |
          cd servers/go-vanilla && go mod tidy
          cd ../go-fiber && go mod tidy
          cd ../hono-bun && bun install

      - name: Run benchmark - ${{ matrix.config.name }}
        run: |
          chmod +x scripts/benchmark.sh
          ./scripts/benchmark.sh \
            --duration ${{ matrix.config.duration }} \
            --connections ${{ matrix.config.connections }} \
            --threads ${{ matrix.config.threads }}

      - name: Upload results - ${{ matrix.config.name }}
        uses: actions/upload-artifact@v4
        with:
          name: monthly-benchmark-${{ matrix.config.name }}-${{ github.run_number }}
          path: results/
          retention-days: 90
